foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
foo <- gsub('#\\w+',"",foo)
df_ind$text_clean <- foo
View(df_ind)
df_ind$text_clean <- foo
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
df_ind$text_clean <- foo
#Retrait des stopwords
foo <- gsub(stopwords("fr"),"",foo)
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des stopwords
foo <- gsub(stopwords("fr"),"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des stopwords
foo <- gsub(stopwords("fr"),"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
stopwords("fr")
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des stopwords
foo <- gsub(stopwords("fr"),"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
#Retrait des stopwords
stpwrd <- stopwords("fr")
foo <- gsub(paste(stpwrd,collapse = "|"),"",foo)
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des stopwords
stpwrd <- stopwords("fr")
foo <- gsub(paste(stpwrd,collapse = "|"),"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
#Retrait des stopwords
stpwrd <- stopwords("fr")
stpwrd
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
foo <- df_ind%>%
count(screen_name)%>%
arrange(desc(n))
foo
vect_these <- c("Evian","Ricard","Dior","Chanel","Total","Renault","Michelin","Carrefour","Decathlon","Sephora","SFR","BouyguesTélécom","EDF")
vect_dior <- "VeuveClicquot"
####PACKAGE STORAGE
library(quanteda)
library(dplyr)
library(tm)
library(stringr)
library(udpipe)
library(syuzhet)
library(seededlda)
library(tidyr)
library(tibble)
library(forcats)
library(ggplot2)
library(tidylo)
library(tidytext)
df_trt <- readRDS("Data_primaires.rds")
table(df_trt$Marque)
df_ind <- df_trt %>%
filter(Marque%in%vect_dior) %>%
select(status_id,screen_name,text,Marque)
vect_these <- c("Evian","Ricard","Dior","Chanel","Total","Renault","Michelin","Carrefour","Decathlon","Sephora","SFR","BouyguesTélécom","EDF")
vect_ <- "VeuveClicquot"
####PACKAGE STORAGE
library(quanteda)
library(dplyr)
library(tm)
library(stringr)
library(udpipe)
library(syuzhet)
library(seededlda)
library(tidyr)
library(tibble)
library(forcats)
library(ggplot2)
library(tidylo)
library(tidytext)
df_trt <- readRDS("Data_primaires.rds")
table(df_trt$Marque)
df_ind <- df_trt %>%
filter(Marque%in%vect_) %>%
select(status_id,screen_name,text,Marque)
#dict <- dictionary("C:/Users/jmonn/Documents/GitHub/Personnalite/adjectifs de marque.xlsx")
dict_brut <- readxl::read_excel("adjectifs de marque.xlsx")
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
vect_cat <- levels(vect_cat)
dict_net <- c()
for (val in vect_cat) {
foo <- dict_brut%>%filter(`Facteur Ocean`==val)
a <- foo$`Pré-Régex`
dict_net[[val]] <- a
}
dict_net <- dictionary(dict_net)
foo <- df_ind%>%
count(screen_name)%>%
arrange(desc(n))
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_ind$text_clean, doc_id = df_ind$status_id)
annot_ud <- as.data.frame(annot_ud)
names(annot_ud)[names(annot_ud) == "doc_id"] <- "status_id"
df_trt_annot <- left_join(annot_ud,df_ind)
View(df_trt_annot)
View(annot_ud)
View(df_trt_annot)
#df_trt_annot <- readRDS("df_prez_dior.rds")
annot_t <- df_trt_annot %>%
filter(upos=="ADJ")
View(annot_t)
mydfm <- dfm(annot_t$token,
tolower = TRUE,
what = "word")
#             groups = foo$Marque)
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.0004,
max_termfreq = 0.01,
termfreq_type ="prop")
mydfm.un.trim
vect_these <- c("Evian","Ricard","Dior","Chanel","Total","Renault","Michelin","Carrefour","Decathlon","Sephora","SFR","BouyguesTélécom","EDF")
vect_ <- "chanel"
####PACKAGE STORAGE
library(quanteda)
library(dplyr)
library(tm)
library(stringr)
library(udpipe)
library(syuzhet)
library(seededlda)
library(tidyr)
library(tibble)
library(forcats)
library(ggplot2)
library(tidylo)
library(tidytext)
df_trt <- readRDS("Data_primaires.rds")
table(df_trt$Marque)
df_ind <- df_trt %>%
filter(Marque%in%vect_) %>%
select(status_id,screen_name,text,Marque)
vect_these <- c("Evian","Ricard","Dior","Chanel","Total","Renault","Michelin","Carrefour","Decathlon","Sephora","SFR","BouyguesTélécom","EDF")
vect_ <- "Chanel"
####PACKAGE STORAGE
library(quanteda)
library(dplyr)
library(tm)
library(stringr)
library(udpipe)
library(syuzhet)
library(seededlda)
library(tidyr)
library(tibble)
library(forcats)
library(ggplot2)
library(tidylo)
library(tidytext)
df_trt <- readRDS("Data_primaires.rds")
table(df_trt$Marque)
df_ind <- df_trt %>%
filter(Marque%in%vect_) %>%
select(status_id,screen_name,text,Marque)
#dict <- dictionary("C:/Users/jmonn/Documents/GitHub/Personnalite/adjectifs de marque.xlsx")
dict_brut <- readxl::read_excel("adjectifs de marque.xlsx")
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
vect_cat <- levels(vect_cat)
dict_net <- c()
for (val in vect_cat) {
foo <- dict_brut%>%filter(`Facteur Ocean`==val)
a <- foo$`Pré-Régex`
dict_net[[val]] <- a
}
dict_net <- dictionary(dict_net)
foo <- df_ind%>%
count(screen_name)%>%
arrange(desc(n))
foo
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
View(df_ind)
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_ind$text_clean, doc_id = df_ind$status_id)
annot_ud <- as.data.frame(annot_ud)
names(annot_ud)[names(annot_ud) == "doc_id"] <- "status_id"
df_trt_annot <- left_join(annot_ud,df_ind)
coo_ud <- cooccurrence(annot_ud,group = "doc_id",term = "lemma",skipgram=3)
coo_ud <- cooccurrence(annot_ud,group = "status_id",term = "lemma",skipgram=3)
coo_ud
coo_ud <- cooccurrence(annot_ud,group = "status_id",term = "lemma",skipgram=2)
coo_ud
View(coo_ud)
annot_ud <- annot_ud%>%anti_join(stop_words,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
coo_ud <- cooccurrence(annot_ud,group = "status_id",term = "lemma",skipgram=2)
annot_adj <- df_trt_annot%>%anti_join(stop_words,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
coo_ud <- cooccurrence(annot_adj,group = "status_id",term = "lemma",skipgram=2)
vect_these <- c("Evian","Ricard","Dior","Chanel","Total","Renault","Michelin","Carrefour","Decathlon","Sephora","SFR","BouyguesTélécom","EDF")
vect_ <- "Chanel"
####PACKAGE STORAGE
library(quanteda)
library(dplyr)
library(tm)
library(stringr)
library(udpipe)
library(syuzhet)
library(seededlda)
library(tidyr)
library(tibble)
library(forcats)
library(ggplot2)
library(tidylo)
library(tidytext)
df_trt <- readRDS("Data_primaires.rds")
table(df_trt$Marque)
df_ind <- df_trt %>%
filter(Marque%in%vect_) %>%
select(status_id,screen_name,text,Marque)
#dict <- dictionary("C:/Users/jmonn/Documents/GitHub/Personnalite/adjectifs de marque.xlsx")
dict_brut <- readxl::read_excel("adjectifs de marque.xlsx")
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
vect_cat <- levels(vect_cat)
dict_net <- c()
for (val in vect_cat) {
foo <- dict_brut%>%filter(`Facteur Ocean`==val)
a <- foo$`Pré-Régex`
dict_net[[val]] <- a
}
dict_net <- dictionary(dict_net)
foo <- df_ind%>%
count(screen_name)%>%
arrange(desc(n))
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_ind$text_clean, doc_id = df_ind$status_id)
annot_ud <- as.data.frame(annot_ud)
names(annot_ud)[names(annot_ud) == "doc_id"] <- "status_id"
df_trt_annot <- left_join(annot_ud,df_ind)
annot_adj <- df_trt_annot%>%anti_join(stop_words,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
coo_ud <- cooccurrence(annot_adj,group = "status_id",term = "lemma",skipgram=2)
View(coo_ud)
View(annot_adj)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
foo <- df_ind$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des #
#foo <- gsub('#\\w+',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait de la ponctuation
foo <- gsub('[[:punct:]]',"",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_ind$text_clean <- foo
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_ind$text_clean, doc_id = df_ind$status_id)
annot_ud <- as.data.frame(annot_ud)
names(annot_ud)[names(annot_ud) == "doc_id"] <- "status_id"
df_trt_annot <- left_join(annot_ud,df_ind)
annot_adj <- df_trt_annot%>%anti_join(stop_words,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
coo_ud <- cooccurrence(annot_adj,group = "status_id",term = "lemma",skipgram=2)
View(coo_ud)
View(annot_adj)
#df_trt_annot <- readRDS("df_prez_dior.rds")
annot_t <- df_trt_annot %>%
filter(upos=="ADJ")
stp_wrd <- stopwords("fr")
annot_adj <- df_trt_annot%>%anti_join(stp_wrd,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
annot_adj <- df_trt_annot%>%anti_join(stp_wrd,by=c("lemma"="word"))%>%filter(upos%in%c("ADJ"))
stop_words
stp_wrd$Mots <- as.data.frame(stp_wrd)
stp_wrd
annot_adj <- df_trt_annot%>%anti_join(stop_words,by=c("token"="Mots"))%>%filter(upos%in%c("ADJ"))
View(annot_adj)
View(stp_wrd)
View(stp_wrd)
stp_wrd <- as.data.frame(stp_wrd)
View(stp_wrd)
stp_wrd <- stopwords("fr")
stp_wrd <- as.data.frame(stp_wrd)
View(stp_wrd)
annot_adj <- df_trt_annot%>%anti_join(stop_words,by=c("token"="stp_wrd"))%>%filter(upos%in%c("ADJ"))
annot_adj <- df_trt_annot%>%anti_join(stp_wrd,by=c("token"="stp_wrd"))%>%filter(upos%in%c("ADJ"))
coo_ud <- cooccurrence(annot_adj,group = "status_id",term = "lemma",skipgram=2)
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.1,
max_termfreq = 0.9,
termfreq_type ="prop")
mydfm <- dfm(annot_adj$token,
tolower = TRUE,
what = "word")
#             groups = foo$Marque)
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.1,
max_termfreq = 0.9,
termfreq_type ="prop")
View(mydfm.un.trim)
mydfm.un.trim
mydfm <- dfm(annot_adj$token,
tolower = TRUE,
what = "word")
mydfm
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.01,
max_termfreq = 0.95,
termfreq_type ="prop")
mydfm.un.trim
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.01,
max_termfreq = 0.99,
termfreq_type ="prop")
mydfm.un.trim
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.001,
max_termfreq = 0.01,
termfreq_type ="prop")
mydfm.un.trim
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.0001,
max_termfreq = 0.01,
termfreq_type ="prop")
mydfm.un.trim
lda <- textmodel_seededlda(
mydfm.un.trim,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
min_termfreq=2,
alpha = NULL,
beta = NULL,
)
terms(lda)
topics(lda)
View(annot_adj)
annot_adj <- df_trt_annot%>%
anti_join(stp_wrd,by=c("token"="stp_wrd"))%>%
filter(upos%in%c("ADJ"))%>%
filter(dep_rel!="amod")
coo_ud <- cooccurrence(annot_adj,group = "status_id",term = "lemma",skipgram=2)
View(coo_ud)
mydfm <- dfm(annot_adj$token,
tolower = TRUE,
what = "word")
#             groups = foo$Marque)
mydfm.un.trim <-
dfm_trim(
mydfm,
min_termfreq = 0.0001,
max_termfreq = 0.01,
termfreq_type ="prop")
mydfm.un.trim
lda <- textmodel_seededlda(
mydfm.un.trim,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
min_termfreq=2,
alpha = NULL,
beta = NULL,
)
terms(lda)
topics(lda)
