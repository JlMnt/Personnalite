---
title: "Word2vec"
author: "Julien Monnot"
date: "09/01/2022"
output: html_document
---

#Lecture des packages et des bases de données
```{r setup}
####PACKAGE STORAGE
library(dplyr)
library(tidyr)
library(ggplot2)
library(tidytext)
library(rtweet)
library(stringi)

#Lecture de la base de tweets primaires sans relecture qualitative
df_trt <- readRDS("Data_primaires.rds")

```
## Lecture des ressources : Vecteurs de tri et dictionnaire
```{r setup2}
#vecteur des marques cibles
vect_these <- c("Chanel")

#lecture du dictionnaire
dict_brut <- readxl::read_excel("adjectifs de marque.xlsx")

#Factorisation des catégories du tableau excel chargé
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
##Lecture des niveaux des catégories
vect_cat <- levels(vect_cat)
##Création d'un vecteur libre pour création dictionnaire
dict_net <- c()

#Création du dictionnaire
for (val in vect_cat) {
  foo <- dict_brut%>%filter(`Facteur Ocean`==val)
  a <- foo$`Pré-Régex`
  dict_net[[val]] <- a
  }
dict_net <- dictionary(dict_net)

```

```{r Filter, eval=FALSE}
#table(df_trt$Marque)
df_ind <- df_trt %>%
  filter(Marque%in%vect_these) %>%
  select(status_id,screen_name,text,Marque)

```

```{r correction, eval=FALSE}
##ne runner que si l'annotation n'a pas encore été faîtes
foo <- df_ind$text

#Retrait des mentions
foo <- gsub("@\\w+","",foo)

#Retrait des #
foo <- gsub('#\\w+',"",foo)

#Retrait des émojis
foo <- str_remove_all(string = foo, pattern = '[:emoji:]')

#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)

#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)

#Retrait des nombres
foo <- gsub('\\d',"",foo)

#Retrait des amp
foo <- gsub('&amp;',"",foo)

#Retrait de la ponctuation
foo <- gsub('[[:punct:]]'," ",foo)

#Retrait des lettres seules
foo <- gsub('\\W*\\b\\w\\b\\W*'," ",foo)

#Retrait des emoticon
#foo <- gsub('[^\x01-\x7F]'," ",foo)

#Retrait des espaces
foo <- gsub('\\s+$',"",foo)

#Retrait des espaces
foo <- gsub('^\\s+',"",foo)

#création d'une nouvelle colonne pour l'annotation
df_ind$text <- foo

```


```{r word2vec}
toks <- tokens(df_ind$text,
               remove_punct = TRUE)

toks_grm <- tokens_ngrams(toks,n=2,skip = 1:2)

toks_neg_grm <- tokens_compound(toks,pattern = phrase("pas "))

toks_neg_grm_sel <- tokens_select(toks_neg_grm,pattern = phrase("pas_*"))
head(toks_neg_grm_sel[[1]])

```

```{r lda}
for (val in vect_these) {
  foo <- dfm_subset(mydfm,Marque==val)

  lda <- textmodel_seededlda(
  foo,
  dict_net,
  valuetype = "regex",
  max_iter = 2000,
  residual = TRUE,
  min_termfreq=2,
  alpha = NULL,
  beta = NULL)

foo <- as.data.frame(terms(lda,20))
foo <- flextable(foo)

foo <- set_caption(foo, caption = val)
print(foo)
#topics(lda)

}


```

