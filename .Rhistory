foo <- gsub('\\W*\\b\\w\\b\\W*'," ",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_tweets_mrq$Text_clean <- foo
df_tweets_mrq$Date <- ceiling_date(df_tweets_mrq$created_at,"weeks")
foo <- df_tweets_mrq%>%
group_by(name,Date)%>%
count(name)%>%
ungroup()
ggplot(foo,aes(Date,n,color=name))+geom_line(show.legend = FALSE)+facet_grid(rows = vars(name))+ ggtitle("Nombre de posts hebdomadaires") + xlab("Année de publication") + ylab("") + labs(caption = "Source: Données collectées via Rtweet sur Twitter")+ guides(fill=guide_legend(title="Marque"))+ylim(0,80)+theme_minimal()# geom_smooth(method=lm , color="lightblue", se=TRUE,size=0.1)
df_tweets_mrq$Date
df_tweets_mrq$Date <- ceiling_date(df_tweets_mrq$created_at,"weeks")
foo <- df_tweets_mrq%>%
group_by(name,Date)%>%
count(name)%>%
ungroup()
foo%>%
group_by(name)%>%
summarise(name=name,Moy=mean(n))%>%
unique()%>%
ggplot(aes(reorder(name,Moy),Moy,fill=name))+geom_bar(stat = "identity",show.legend = FALSE)+coord_flip()+ xlab("") + ylab("Moyenne hebdomadaire de publications")+ labs(caption = "Source: Données collectées via Rtweet sur Twitter")
df_tweets_mrq <- df_tweets_mrq%>%
mutate(Type=ifelse(is_retweet=="TRUE","Retweets",
ifelse(is_quote=="TRUE"&is.na(reply_to_screen_name),"Quotes",
ifelse(!is.na(reply_to_screen_name),"Replies","Primaires"))))%>%
mutate(dte = year(created_at),
wek = week(created_at),
grp_twt= paste0(dte,wek),
Marque = paste0(name,dte))
View(df_tweets_mrq)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
#On charge lespackages
library(dplyr)
library(stringr)
library(ggplot2)
library(lubridate)
library(tidyverse)
library(udpipe)
library(tidytext)
library(textdata)
library(syuzhet)
library(quanteda)
library(quanteda.textstats)
library(FactoMineR)
library(factoextra)
library(knitr)
library(ggpubr)
date <- Sys.Date()
#lecture du dictionnaire
dict_brut <- readxl::read_excel("adjectifs de marque.xlsx")
#Factorisation des catégories du tableau excel chargé
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
##Lecture des niveaux des catégories
vect_cat <- levels(vect_cat)
##Création d'un vecteur libre pour création dictionnaire
dict_net <- c()
#Création du dictionnaire
for (val in vect_cat) {
foo <- dict_brut%>%filter(`Facteur Ocean`==val)
a <- foo$Regex_lda
dict_net[[val]] <- a
}
dict_net <- dictionary(dict_net)
#On crée un vecteur réunissant les noms des tweets des marques requêtées
data <- (Sys.glob("*.rds"))
data <- as.data.frame(data)%>%
filter(str_detect(data,"tweets"))%>%
as.list(data)%>%
unlist()
list_df <- lapply(data, function(x) readRDS(x))
#Bind
df_tweets_mrq <- bind_rows(list_df)
#Unique test
doublons <- which(duplicated(df_tweets_mrq$status_id))
df_tweets_mrq <- df_tweets_mrq[-doublons,]
#df_tweets_mrq <- df_tweets_mrq%>%filter(is_retweet=="FALSE")
df_tweets_mrq <- df_tweets_mrq %>%
filter(lang=="fr")%>%
group_by(name)%>%
mutate(name=strsplit(name," ")[[1]][1])
#Retrait des @,url,sauts de lignes, espaces
foo <- df_tweets_mrq$text
#Retrait des mentions
foo <- gsub("@\\w+","",foo)
#Retrait des #
foo <- gsub('#\\w+',"",foo)
#Retrait des émojis
foo <- str_remove_all(string = foo, pattern = '[:emoji:]')
#Retrait des sauts de lignes
foo <- gsub('\n',"",foo)
#Retrait des URL
foo <- gsub('http\\S+\\s*',"",foo)
#Retrait des nombres
foo <- gsub('\\d',"",foo)
#Retrait des amp
foo <- gsub('&amp;',"",foo)
#Retrait de la ponctuation
foo <- gsub('[[:punct:]]'," ",foo)
#Retrait des lettres seules
foo <- gsub('\\W*\\b\\w\\b\\W*'," ",foo)
#Retrait des espaces
foo <- gsub('\\s+$',"",foo)
#Retrait des espaces
foo <- gsub('^\\s+',"",foo)
df_tweets_mrq$Text_clean <- foo
df_tweets_mrq <- df_tweets_mrq%>%
mutate(Type=ifelse(is_retweet=="TRUE","Retweets",
ifelse(is_quote=="TRUE"&is.na(reply_to_screen_name),"Quotes",
ifelse(!is.na(reply_to_screen_name),"Replies","Primaires"))))%>%
mutate(dte = year(created_at),
wek = week(created_at),
grp_twt= paste0(dte,wek),
Marque = paste0(name,dte))
View(df_tweets_mrq)
df_tweets_mrq <- df_tweets_mrq%>%
mutate(Type=ifelse(is_retweet=="TRUE","Retweets",
ifelse(is_quote=="TRUE"&is.na(reply_to_screen_name),"Quotes",
ifelse(!is.na(reply_to_screen_name),"Replies","Primaires"))))%>%
mutate(dte = year(created_at),
wek = week(created_at),
grp_twt= paste0(dte,wek,name))
df_tweets_mrq <- df_tweets_mrq%>%
mutate(Type=ifelse(is_retweet=="TRUE","Retweets",
ifelse(is_quote=="TRUE"&is.na(reply_to_screen_name),"Quotes",
ifelse(!is.na(reply_to_screen_name),"Replies","Primaires"))))%>%
mutate(dte = year(created_at),
wek = week(created_at),
grp_twt= paste0(dte,wek,name))%>%
filter(Type=="Primaires")
df_tweets_mrq <- df_tweets_mrq%>%
mutate(Type=ifelse(is_retweet=="TRUE","Retweets",
ifelse(is_quote=="TRUE"&is.na(reply_to_screen_name),"Quotes",
ifelse(!is.na(reply_to_screen_name),"Replies","Primaires"))))%>%
mutate(dte = year(created_at),
wek = week(created_at),
grp_twt= paste0(dte,wek,name))%>%
filter(Type=="Primaires")
#Factorisation des catégories du tableau excel chargé
vect_cat <- as.factor(dict_brut$`Facteur Ocean`)
##Lecture des niveaux des catégories
vect_cat <- levels(vect_cat)
##Création d'un vecteur libre pour création dictionnaire
dict_net_light <- c()
df_toks <- data.frame()
df_foo <- df_tweets_mrq%>%
group_by(name,status_id,Text_clean)%>%
filter(Type=="Organiques")%>%
mutate(Text_cleanTok =Text_clean)%>%
unnest_tokens(Toks,Text_cleanTok)
#table(str_detect(df_foo$Toks,"ambi"))
for (val in vect_cat) {
foo <- dict_brut%>%filter(`Facteur Ocean`==val)
list_regex_ocean <- foo$Regex_detec
list_regex_ocean <- paste0("\\b",list_regex_ocean,"\\b", collapse="|")
foo <- df_foo
foo$Presence <- str_detect(foo$Toks,list_regex_ocean)
foo<-foo%>%
filter(Presence=="TRUE")
print(foo)
df_toks<-rbind(df_toks,foo)
}
##suppression des adverbes
library(SnowballC)
df_toks<-df_toks%>%
mutate(ADV=str_detect(Toks,"ement"))%>%
filter(ADV=="FALSE")%>%
mutate(Stem=wordStem(Toks))
vect_stem <- levels(as.factor(df_toks$Stem))
vect_stem <- paste0("\\b",vect_stem, collapse="|")
dict_brt<-dict_brut%>%
mutate(OCEAN=str_detect(`Français ( lemme) ( Première lettre minuscule)`,vect_stem))%>%
filter(OCEAN=="TRUE")
#Création du dictionnaire
for (val in vect_cat) {
foo <- dict_brt%>%filter(`Facteur Ocean`==val)
a <- foo$Regex_lda
dict_net_light[[val]] <- a
}
dict_net_light <- dictionary(dict_net_light)
###déja téléchargée df_trt_annot
#udpipe_download_model("french")
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_annot$Text_clean, doc_id = df_annot$status_id)
df_annot <- df_tweets_mrq
###déja téléchargée df_trt_annot
#udpipe_download_model("french")
udmodel <- udpipe_load_model("french-gsd-ud-2.5-191206.udpipe")
annot_ud <- udpipe_annotate(udmodel,df_annot$Text_clean, doc_id = df_annot$status_id)
annot_ud <- as.data.frame(annot_ud)
names(annot_ud)[names(annot_ud) == "doc_id"] <- "status_id"
df_trt_annot <- left_join(annot_ud,df_annot)
#saveRDS(df_trt_annot,"Annotation_220125.rds")
df_trt_adj <- df_trt_annot%>%
filter(upos=="ADJ")%>%
mutate(Nbcar=nchar(lemma),Mention=str_detect(lemma,"\\@"))%>%
filter(Nbcar>2,Mention=="FALSE")
View(df_trt_adj)
View(df_annot)
View(df_trt_annot)
df_trt_adj <- df_trt_annot%>%
filter(upos=="ADJ")
View(df_trt_adj)
grp_filt <- levels(as.factor(df_trt_adj$grp_twt))
grp_filt
View(df_trt_adj)
View(df_annot)
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
grp_filt
foo <- df_trt_adj%>%
filter(grp_twt==val)
foo
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
}
View(foo)
df_buff <- unique(foo$Marque)
df_buff
df_buff <- unique(foo$name)
df_buff
df_buff$name <- unique(foo$name)
df_buff$Marque <- unique(foo$Marque)
df_buff$Text <- paste0(foo$Text_clean)
df_buff
View(foo)
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_tweets_mrq%>%
filter(grp_twt==val)
df_grp$name <- unique(foo$name)
df_grp$Marque <- unique(foo$Marque)
df_grp$Text <- paste0(foo$Text_clean)
}
View(foo)
df_grp$name <- unique(foo$name)
df_grp
df_grp$name
unique(foo$name)
df_grp <- data.frame()
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_tweets_mrq%>%
filter(grp_twt==val)
df_grp$name <- unique(foo$name)
df_grp$Marque <- unique(foo$Marque)
df_grp$Text <- paste0(foo$Text_clean)
}
name<-unique(foo$name)
text<-paste0(foo$Text_clean)
text
df_grp$name <- name
df_grp <- data.frame()
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_tweets_mrq%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean)
df_grp$name <- name
df_grp$text <- text
}
df_foo<-cbind(name,text)
df_foo
text<-paste0(foo$Text_clean,collapse = "/n")
df_foo<-cbind(name,text)
df_foo
df_foo<-rbind(name,text)
df_foo
df_foo<-cbind(name,text)
name
text
text<-paste0(foo$Text_clean,collapse = "\n")
text
text<-paste0(foo$Text_clean,collapse = "")
text
text<-paste0(foo$Text_clean,collapse = " ")
text
df_foo<-cbind(name,text)
df_foo
df_foo<-data.frame()
df_foo<-cbind(name,text)
df_foo
df_foo<-data.frame()
df_foo<-cbind(name,text)
df_foo
df_foo<-as.data.frame()
df_foo<-as.data.frame(df_foo)
df_foo
df_foo<-cbind(name,text)
df_foo<-as.data.frame(df_foo)
df_foo
View(df_foo)
rbind(df_grp,df_foo)
df_grp<- rbind(df_grp,df_foo)
df_grp
View(df_grp)
df_grp <- data.frame()
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_tweets_mrq%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
df_foo<-cbind(name,text)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
View(df_grp)
View(df_grp)
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_tweets_mrq%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
View(df_grp)
View(df_grp)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
foo
df_grp
View(df_grp)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
docvars(foo,"Marque")<-df_grp$name
library(seededlda)
library(flextable)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
docvars(foo,"Marque")<-df_grp$name
lda <- textmodel_seededlda(
foo,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
alpha = NULL,
beta = NULL)
foo <- terms(lda,n=20)
foo <- as.data.frame(foo)
foo<-foo%>%select(1:11)
#print(kable(foo, caption = "Adjectifs des Marques"))
foo <- as.data.frame(foo)
print(foo)
library(seededlda)
library(flextable)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
docvars(foo,"Marque")<-df_grp$name
lda <- textmodel_seededlda(
foo,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
alpha = NULL,
beta = NULL)
foo <- terms(lda,n=20)
foo <- as.data.frame(foo)
foo<-foo%>%select(1:11)
#print(kable(foo, caption = "Adjectifs des Marques"))
foo <- as.data.frame(foo)
print(foo)
print(foo)
View(foo)
View(foo)
View(df_trt_adj)
foo <- df_trt_adj%>%
filter(grp_twt==val)
View(foo)
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
name
grp_filt <- levels(as.factor(df_tweets_mrq$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
grp_filt <- levels(as.factor(df_trt_adj$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
View(df_grp)
library(seededlda)
library(flextable)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
docvars(foo,"Marque")<-df_grp$name
lda <- textmodel_seededlda(
foo,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
alpha = NULL,
beta = NULL)
foo <- terms(lda,n=20)
foo <- as.data.frame(foo)
foo<-foo%>%select(1:11)
#print(kable(foo, caption = "Adjectifs des Marques"))
foo <- as.data.frame(foo)
print(foo)
View(foo)
grp_filt <- levels(as.factor(df_trt_adj$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$Text_clean,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
View(foo)
grp_filt <- levels(as.factor(df_trt_adj$grp_twt))
df_grp <- data.frame()
for (val in grp_filt) {
foo <- df_trt_adj%>%
filter(grp_twt==val)
name<-unique(foo$name)
text<-paste0(foo$lemma,collapse = " ")
dt <- unique(foo$grp_twt)
df_foo<-cbind(name,text,dt)
df_foo<-as.data.frame(df_foo)
df_grp<- rbind(df_grp,df_foo)
}
View(df_grp)
library(seededlda)
library(flextable)
foo <- dfm(df_grp$text,remove_padding = TRUE,tolower = TRUE)
docvars(foo,"Marque")<-df_grp$name
lda <- textmodel_seededlda(
foo,
dict_net,
valuetype = "regex",
max_iter = 2000,
residual = TRUE,
alpha = NULL,
beta = NULL)
foo <- terms(lda,n=20)
foo <- as.data.frame(foo)
foo<-foo%>%select(1:11)
#print(kable(foo, caption = "Adjectifs des Marques"))
foo <- as.data.frame(foo)
print(foo)
View(foo)
ld <- as.data.frame(lda$data@docvars)
lt <- as.data.frame(lda$theta)
lt$docname_ <- rownames(lt)
data <- inner_join(ld,lt,by="docname_")
data<- data[4:14]
df <- data%>%
pivot_longer(-Marque,names_to = "facteurs",values_to = "Scores")%>%
mutate(Groupe=ifelse(str_detect(facteurs,"\\+"),1,0))%>%
filter(facteurs!="other")%>%
group_by(Marque,facteurs,Groupe)%>%
summarise(Scores_mn = mean(Scores,na.rm=TRUE), Score_sd = sd(Scores,na.rm = TRUE))%>%
mutate(Scores=ifelse(Groupe==0,-Scores_mn,Scores_mn))%>%
mutate(Dim=substring(facteurs,1,1))%>%
filter(Groupe==1)
gg1 <- ggplot(df,aes(x=reorder(Dim,Scores),y=Scores,group=Groupe)) + geom_line(aes(color=Groupe)) + geom_ribbon(aes(ymin=Scores_mn - Score_sd,ymax=Scores_mn + Score_sd), alpha=0.2) + facet_wrap(vars(Marque)) + coord_flip()
print(gg1)
gg0 <- ggplot(df,aes(x=reorder(Dim,Scores),y=Scores,group=Groupe)) + geom_line(aes(color=Groupe)) + facet_wrap(vars(Marque)) + coord_flip()
print(gg0)
df <- data%>%
pivot_longer(-Marque,names_to = "facteurs",values_to = "Scores")%>%
mutate(Groupe=ifelse(str_detect(facteurs,"\\+"),1,0))%>%
filter(facteurs!="other")%>%
group_by(Marque,facteurs,Groupe)%>%
summarise(Scores_mn = mean(Scores,na.rm=TRUE), Score_sd = sd(Scores,na.rm = TRUE))%>%
mutate(Scores=ifelse(Groupe==0,-Scores_mn,Scores_mn))%>%
mutate(Dim=substring(facteurs,1,1))%>%
filter(Groupe==0)
gg1 <- ggplot(df,aes(x=reorder(Dim,Scores),y=Scores,group=Groupe)) + geom_line(aes(color=Groupe)) + geom_ribbon(aes(ymin=-Scores_mn - Score_sd,ymax=-Scores_mn + Score_sd), alpha=0.2) + facet_wrap(vars(Marque)) + coord_flip()
print(gg1)
gg0 <- ggplot(df,aes(x=reorder(Dim,Scores),y=Scores,group=Groupe)) + geom_line(aes(color=Groupe)) + facet_wrap(vars(Marque)) + coord_flip()
print(gg0)
